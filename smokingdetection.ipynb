{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoking Detection using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Florian Rieser, June 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project goal/Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The No Smoking signs at gas stations are essential for safety, not just regulatory requirements. The main hazard at these locations is invisible: gasoline vapors. Using a FLIR Optical Gas Imaging camera, these unseen vapors become visible as a highly flammable black cloud that could ignite with minimal provocation. There are various methods to detect smoking, such as smoke detectors, gas sensors (e.g., carbon monoxide and VOC sensors), particulate matter sensors, thermal cameras, acoustic sensors, and chemical sensors. Although effective, these methods can be expensive to implement.\n",
    "\n",
    "This project aims to provide a more affordable solution by utilizing artificial intelligence. By training an artificial neural network to recognize smoking behavior based on pictures of individuals, we can develop an alert system that ensures safety without the need for costly specialized equipment. This model can then be combined with an object detection system to identify individuals and detect smoking, triggering necessary alerts. By leveraging the existing surveillance cameras typically found at gas stations, this AI-based approach offers a cost-effective and efficient way to prevent accidents caused by smoking in restricted areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we utilized a dataset from Kaggle (https://www.kaggle.com/datasets/sujaykapadnis/smoking), specifically designed for smoker detection. The dataset consists of 1,120 images, equally divided into two classes: 560 images of smokers and 560 images of non-smokers. These images were collected by searching various keywords across multiple search engines, including terms such as cigarette smoking, smoker, person, coughing, taking inhaler, person on the phone, and drinking water. This approach ensured a diverse set of images for each category.\n",
    "\n",
    "To enhance the model's training and introduce a degree of inter-class confusion, the dataset includes versatile images within both classes. The Smoking class features images of individuals smoking from different angles and in various gestures. In contrast, the NotSmoking class contains images of non-smokers performing actions that could resemble smoking, such as drinking water, using an inhaler, holding a mobile phone, or coughing. This careful selection improves the model's ability to accurately differentiate between smokers and non-smokers.\n",
    "\n",
    "All images were preprocessed and resized to a resolution of 250×250 pixels. The dataset was split, with 80% used for training and validation and the remaining 20% for testing. This dataset is a valuable resource for developing deep learning algorithms for automated smoker detection, contributing to environmental sustainability and enhancing surveillance in smart cities.\n",
    "\n",
    "Citation: Khan, Ali (2022), “Smoker Detection Dataset”, Mendeley Data, V1, doi: 10.17632/j45dj8bgfc.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training/Fine-tuning of a self-developed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the training and validation directories\n",
    "train_dir = 'training_images'\n",
    "validation_dir = 'validation_images'\n",
    "\n",
    "# Define the image size and batch size\n",
    "image_size = (250, 250) # All images will be resized to 250x250\n",
    "batch_size = 32 # Number of images to process at a time\n",
    "num_epochs = 500 # Number of epochs to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from directory\n",
    "def load_images_from_directory(directory, target_size=(250, 250)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(directory))  # Get sorted list of class names\n",
    "    label_to_index = {class_name: i for i, class_name in enumerate(class_names)}  # Map class name to numerical label\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            image_path = os.path.join(class_dir, filename)\n",
    "            image = Image.open(image_path)\n",
    "            image = image.resize(target_size)\n",
    "            image = np.array(image) / 255.0  # Normalize pixel values\n",
    "            images.append(image)\n",
    "            labels.append(label_to_index[class_name])  # Append numerical label\n",
    "    return np.array(images), np.array(labels), class_names\n",
    "\n",
    "# Load and preprocess the training, validation, and testing datasets\n",
    "train_images, train_labels, train_class_labels = load_images_from_directory(train_dir)\n",
    "validation_images, validation_labels, validation_class_labels = load_images_from_directory(validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model for binary classification\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(250, 250, 3)),  # Define input shape\n",
    "    data_augmentation, \n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)), \n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation='relu'), \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') # Use 'sigmoid' for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) \n",
    "\n",
    "# Compile the model with the custom optimizer\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and save the training history\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=(validation_images, validation_labels),\n",
    "    callbacks=[early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy and loss values\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model with the incremented version number\n",
    "def get_latest_version_number():\n",
    "    if not os.path.exists('models'):\n",
    "        return 0\n",
    "    model_files = os.listdir('models')\n",
    "    version_numbers = [int(re.search(r'_v(\\d+)\\.keras', filename).group(1)) for filename in model_files if re.search(r'_v(\\d+)\\.keras', filename)]\n",
    "    if version_numbers:\n",
    "        return max(version_numbers)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def save_model_with_version(model):\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')  # Create the 'models' folder if it does not exist\n",
    "    latest_version = get_latest_version_number()\n",
    "    version = latest_version + 1\n",
    "    model_path = f'models/smokingdetector_v{version}.keras'\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved as {model_path}\")\n",
    "\n",
    "save_model_with_version(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interpretation and validation of results & model performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "latest_version = get_latest_version_number()\n",
    "model_path = f'models/smokingdetector_v{latest_version}.keras'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "loss, accuracy = model.evaluate(validation_images, validation_labels)\n",
    "print(f\"Validation Loss: {loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "predictions = model.predict(validation_images)\n",
    "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate and print AUC-ROC\n",
    "auc_roc = roc_auc_score(validation_labels, predictions)\n",
    "print(f\"AUC-ROC: {auc_roc}\")\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(validation_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['not smoking', 'smoking'], yticklabels=['not smoking', 'smoking'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate True Positives (TP), False Positives (FP), False Negatives (FN)\n",
    "TP = np.sum((predicted_labels == 1) & (validation_labels == 1))\n",
    "FP = np.sum((predicted_labels == 1) & (validation_labels == 0))\n",
    "FN = np.sum((predicted_labels == 0) & (validation_labels == 1))\n",
    "\n",
    "# Calculate Precision and Recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply the model to your own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "latest_version = get_latest_version_number()\n",
    "model_path = f'models/smokingdetector_v{latest_version}.keras'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Load and preprocess the image you want to predict\n",
    "image_path = \"path_to_your_image.jpg\"  # Replace \"path_to_your_image.jpg\" with the path to your image\n",
    "image = Image.open(image_path)\n",
    "image = image.resize((250, 250))  # Resize the image to match the input size of the model\n",
    "image = np.array(image) / 255.0  # Normalize pixel values\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(np.expand_dims(image, axis=0))\n",
    "\n",
    "# Interpret predictions\n",
    "if predictions[0][0] > 0.5:\n",
    "    print(\"The model predicts that the image contains smoking behavior.\")\n",
    "else:\n",
    "    print(\"The model predicts that the image does not contain smoking behavior.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
